---
title: "Análisis del precio de la vivienda y el salario medio"
author:
- name: Rodrigo Juanes Busolo
- name: Noe Lopez garcia
- name: Marc Velasco Mateu
output:
  pdf_document: default
  html_notebook: default
  html_document:
    df_print: paged
---

```{r limpieza, include=FALSE}
rm(list = ls())
```

```{r carga de librerias, include=FALSE}
library(readr)
library(knitr)
library(kableExtra)
library(ggplot2)
library(scales)
library(patchwork)
library(plotly)
library(lubridate)
library(corrplot)
library(tidyverse)
library(forcats)
library(visdat)
library(dplyr)
library(tidyr)
library(gganimate)
library(mapSpain)
library(viridis)  # Para una escala de colores visualmente atractiva
#remotes::install_github("jthomasmock/gtExtras")
library(gt)
library(gtExtras)
library(shiny)
```

```{r colores, include=FALSE}
#Colores para comunidades autónomas
coloresCCAA <- c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", "#FFFF33", "#A65628", "#984EA3", "#999999", "#FFC0CB", "#00FF00", "#FF00FF", "#0000FF", "#FFD700", "#000000", "#666666",  "#00FFFF", "#FF4500", "#581845", "#123705", "#9588dd")

#Colores para la partición
coloresparticiónCCAA <- c("#E41A1C", "#FFFF33", "#A65628", "#00FF00", "#FF00FF", "#000000")

#Colores para sexo
coloresHM <- c( "#377EB8","#FFC0CB")

#Colores para tipos de vivienda
coloresNS <- c( "#ffdb4d","#4DAF4A")
```

```{r ccaa, include=FALSE}
#Partición de comunidades autónomas
particionCCAA <- c("Total Nacional", "Balears, Illes", "Canarias", "Cataluña", "Comunitat Valenciana", "Madrid, Comunidad de")
```

# Introducción

En este proyecto, se analiza la evolución de los precios de la vivienda en España en comparación con los salarios medios, con un enfoque especial en el precio por metro cuadrado en la ciudad de Valencia. El objetivo principal es explorar tendencias, identificar posibles disparidades y ofrecer un análisis detallado basado en datos. Este trabajo busca aplicar técnicas de análisis exploratorio de datos (EDA) para extraer información relevante que pueda ser de utilidad para futuros trabajos.

```{r carga datasets, include=FALSE}
# Especificamos que la columna total de Salario sea de tipo character para no perder las comas al importarlo como double
Salario <- read_delim("../data/Salario.csv", delim = ";", escape_double = FALSE, col_types = cols(Total = col_character()), trim_ws = TRUE)
# Con vivienda no es necesario porque como se ve en la herramienta la columna se importa como character
Vivienda <- read_delim("../data/Vivienda.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)
# Leer el dataset de fotocasa
fotocasa_compra <- read.csv("../data/precio-de-compra-en-fotocasa.csv", header = TRUE, sep = ";")
```

## Carga y ajuste del dataset: Salario

Estudiemos el contenido del dateset Salario, formado por 4860 registros de 5 variables.

### Variables en el dataset

Inicialmente ejecutamos el comando str para observar el aspecto que tienen los datos. Además, este comando nos permite visualizar el tipo de dato que contiene cada columna, lo que nos permite visualizar si alguna de ellas debería ser convertida a otro tipo de dato más acorde a la información que contiene.

```{r str salario, include=FALSE}
str(Salario)
# Como se puede ver el problema de la variable Total es que tiene comas y puntos,
# pero en R las comas no son interpretadas con la intención del archivo
```

A continuación, describimos todas las variables presentes.

En primer lugar, `Sexo` es una variable de tipo `string` que refleja si estamos teniendo en cuenta a los hombres, las mujeres o a ambos.

A continuación tenemos la variable `Comunidades autónomas` que es de tipo `string` y que refleja los distintos nombres de las comunidades autónomas de nuestro país.

Por otro lado, la variable `Medias y percentiles` es de tipo `string` y refleja el tanto por ciento de personas que tienen un salario inferior a este.

Seguidamente, tenemos la variable `periodo` que es de tipo `numérico` y que nos indica el año que estamos tratando.

Por último, tenemos la variable `Total` que es de tipo `string`y refleja el valor del salario en €.

En nuestro caso, para el fichero de salario se detectó que la variable total contenía un tipo de dato str, cuando lo lógico es que esta columna sea de tipo numérico. Esto se realizó de manera intencionada al importar los datos, dado que en el INE se emplean comas para separar los decimales, algo que en R se realiza con puntos. Por ello, y para evitar conflictos; se importó como una cadena de texto y luego se realizaron las operaciones siguientes para darle el formato adecuado. Primeramente, como el punto también fue empleado para mostrar la separación de los miles, se sustituyó este elemento por vacío. Seguidamente, las comas fueron sustiuidas por puntos, para finalmente mediante el comando as.numeric convertir los datos de tipo string a numeric.

Además, dado que la variable de medias y percentiles es de tipo categórico y solo puede tomar un número finito de valores, esta fue convertida a factor. Del mismo modo, realizaremos esta conversión con la variable sexo.

```{r ajuste preliminar de salario, echo=FALSE}
# Pasamos a cambiar el formato, y una vez con este correcto hacer un casteo a numérico
# Primero eliminamos los puntos, que se emplean en el archivo original para hacer la
#distinción de 1000
Salario$Total<-gsub(pattern = '[.]',replacement = '',Salario$Total)
# Seguidamente cambiamos las comas por puntos para adecuarlo al formato de R
Salario$Total<-gsub(pattern = '[,]',replacement = '.',Salario$Total)
# Ahora finalmente hacemos el casteo a numeric
Salario$Total<-as.numeric(Salario$Total)
# Además la variable media y percentiles solo puede tener esos valores, por lo que la 
#transformamos en un factor y por fines visuales lo ordenamos, aunque determinar que valor es mayor si la media o la mediana no tine mucho sentido a nivel estadístico
Salario$`Medidas y percentiles` <- factor(Salario$`Medidas y percentiles`, 
                                           levels = c("Percentil 10", "Cuartil inferior",
                                                      "Mediana","Media", "Cuartil superior", "Percentil 90"), 
                                           labels = c("Percentil 10", "Cuartil inferior", 
                                                      "Mediana","Media", "Cuartil superior", "Percentil 90"),
                                           ordered = TRUE)
# Ahora con la variable sexo
inter2<-as.factor(Salario$Sexo)
Salario$Sexo<-factor(inter2,levels = levels(inter2),labels = levels(inter2))
```

### Datos faltantes

Busquemos en el fichero de Salario la presencia de algún dato faltante.

```{r datos faltantes en salario, echo=FALSE}
# Por último comprobamos que no tenemos ningún dato perdido
vis_miss(Salario)
```

Afortunadamente, en el caso de este fichero no se encontraron datos faltantes, por lo que en este caso no fue necesario emplean ningún método para solucionar esto.
 
### Fin de la preparación del dataset

Finalmente guardamos el nuevo fichero con los cambios.

```{r guardar el nuevo dataset salario, include=FALSE}
save(Salario,file = '../data/Salario_clean.csv')
```

## Carga y ajuste del dataset: Vivienda

A continuación, estudiaremos el contenido del dataset Vivienda formado por 1920 registros de 5 variables. 

### Variables en el dataset

Empecemos estudiando las variables presentes en el dataset. Ejecutamos el comando str para ver los tipos de datos existentes, y si estos son coherentes con la información que almacenan.

```{r str vivienda, include=FALSE}
str(Vivienda)
```

Describimos a continuación las variables del dataset.

En primer lugar, tenemos la variable `Comunidades y Ciudades Autónomas`, donde se almacenan los distintos nombres de las comunidades y ciudades autónomas españolas. Esta variable es de tipo `string`, lo cual es adecuado.

A continuación, tenemos la variable `General, vivienda nueva y de segunda mano`, una variable que recoge tres tipos distintos de vivienda, general, nueva y de segunda mano. A pesar de que esta variable es de tipo `string`, la cambiaremos a una variable de tipo `factor`, pues es una variable que solo puede tener tres valores distintos fijos.

La variable `Índices y tasas` es similar, indicando si los datos se refieren a índices o tasas. De igual manera, transformaremos esta variable de `string` a `factor`.

En la variable `Periodo` se encuentran los años de 2007 a 2021. Es de tipo `numeric`, y aunque podríamos cambiarla a tipo `date`, no es realmente necesario.

Por último, `Total` tiene valores exclusivamente numéricos, y con decimales indicados por una coma. Debido a la lectura de la coma como un carácter, esta variable ha sido registrada como un dato `string`. Sustituiremos la coma por un punto y transformaremos esta variable a `numeric`.

```{r ajuste preliminar de vivienda, echo=FALSE, message=FALSE, warning=FALSE}
# Aquí de igual manera que arriba debemos cambiar las comas a puntos para poder hacer el casteo a numeric
Vivienda$Total<-gsub(pattern = '[,]',replacement = '.',Vivienda$Total)
Vivienda$Total<-as.numeric(Vivienda$Total)

# Transformamos ambas variables "General, vivienda nueva y de segunda mano" y "Índices y tasas" a factores, por sus limitados posibles valores
Vivienda$`General, vivienda nueva y de segunda mano` <- factor(Vivienda$`General, vivienda nueva y de segunda mano`, 
                                           levels = c("General", "Vivienda nueva", "Vivienda segunda mano"),
                                           labels = c("General", "Vivienda nueva", "Vivienda segunda mano"),
                                           ordered = FALSE)

Vivienda$`Índices y tasas` <- factor(Vivienda$`Índices y tasas`, 
                                           levels = c("Media anual", "Variación anual"),
                                           labels = c("Media anual", "Variación anual"),
                                           ordered = FALSE)

#Ajustamos los nombres de las comunidades y ciudades
Vivienda$`Comunidades y Ciudades Autónomas` <- substr(Vivienda$`Comunidades y Ciudades Autónomas`, 4, nchar(Vivienda$`Comunidades y Ciudades Autónomas`))
Vivienda$`Comunidades y Ciudades Autónomas`[Vivienda$`Comunidades y Ciudades Autónomas` == "ional"] <- "Total Nacional"
```

### Datos faltantes

A continuación, estudiamos la posible existencia de datos faltantes en nuestro dataset.

```{r datos faltantes en vivienda, echo=FALSE}
# Por último comprobamos si tenemos algún dato perdido
vis_miss(Vivienda)
```

Como podemos observar, el dataset Vivienda sí tiene algunos datos faltantes en la variable "Total". Utilizando de nuevo el comando `str`, vemos que nuestro dataset no tiene ningún valor del IPV de las viviendas nuevas y de segunda mano en Ceuta y Melilla.

```{r encontrar datos faltantes en vivienda, include=FALSE}
# Buscamos dónde están dichos datos faltantes
str(Vivienda[is.na(Vivienda$Total),])
```

Podemos lidiar con estos datos faltantes de distintas maneras. Podemos eliminar las ciudades autónomas de Ceuta y Melilla, y estudiar tan solo el resto de datos, podemos mantener el dataset en este estado y simplemente obviar el análisis de vivienda nueva o de segunda mano en estas ciudades, o podemos tratar de imputar valores nuevos.

En nuestro caso, dado que los datos son proporcionados por la INE, y posiblemente sean calculados a partir de una enorme cantidad y factores que no están a nuestra disposición, optaremos por dejar los datos tal y como están, aunque esto nos prive de analizar los distintos tipos de vivienda en las ciudades autónomas.

### Fin de la preparación del dataset

Después de los cambios realizados, nuestro dataset está listo pata ser analizado. Para conservar nuestros cambios, guardamos el nuevo fichero.

```{r guardar el nuevo dataset vivienda, include=FALSE}
save(Vivienda,file = '../data/Vivienda_clean.csv')
```

## Carga y ajuste del dataset: Precio M2 Valencia

En este último apartado de proceso de carga y ajuste de conjunto de datos, se procede a examinar el conjunto de precios del metro cuadrado por barrio en la ciudad de Valencia en los años 2010 y 2022.

```{r lectura dataset Valencia, echo=FALSE}
#Leer el dataset
fotocasa_compra <- read.csv("../data/precio-de-compra-en-fotocasa.csv", header = TRUE, sep = ";")
```
 
El conjunto de la plataforma Fotocasa responde al precio del metro cuadrado para la compra de viviendas en la ciudad de Valencia. Se presentan datos de precio en los años de 2010 (`Precio_2010 (Euros/m2)`) y 2022(`Precio_2022 (Euros/m2)`), con información sobre el distrito (`DISTRITO`), barrio(`BARRIO`), precio de metro cuadrado (`Max_historico (Euros/m2)`) y máximos históricos (`Año_Max_Hist`). Las columnas Geo.Point (`Geo.Point`) y Geo.Shape (`Geo.Shape`) contienen información sobre las coordenadas geográficas sobre el bario y su entensión en la ciudad de valencia. Referente a los códigos, el de distrito (`coddistrit`) diferencia unequívocamente los distritos de la ciudad de Valencia, mientras que el de barrio (`codbarrio`) numeran los distintos barrios que conforman el distrito. Por ello, la columna de codigo de distrito/barrio (`coddistbar`) identifica de forma única cada barrio de la ciudad de Valencia. Por ejemplo, el barrio de Benimamet tiene el código 1 del distrito de Poblados del Oeste, que tiene código de distrito 18. Por lo tanto su código de distrito/barrio sería 181.


### Renombramiento columnas
El primer paso consiste en renombrar las columnas a nombres más sencillos y fáciles de trabajar, asi como eliminar la columna de fecha, que no aporta información relevante para el análisis[(`GEO_P`,`GEO_S`, `CODDISTBAR`, `CODBAR`, `CODDIS`, `DISTRITO`, `M2_2022`, `M2_2010`, `M2_MAX`, `AÑO_MAX`, `BARRIO`)].
 
```{r dropeo y rename columnas, echo=FALSE}
#Drop de columna FECHA
fotocasa_compra$Fecha_creacion <- NULL

#Renombrar columnas
colnames(fotocasa_compra) <- c("GEO_P","GEO_S", "CODDISTBAR", "CODBAR", "CODDIS", "DISTRITO", "M2_2022", "M2_2010", "M2_MAX", "AÑO_MAX", "BARRIO")
```

### Comprobación de tipos

```{r str, echo=FALSE}
#Resumen de la estructura del dataset
str(fotocasa_compra)
```

A la vista de la estructura del dataset, se observa que la mayoría de las variables son de tipo numérico, excepto aquellas de coordenadas geográficas que son de tipo character, así como el distrito, el barrio o el año (siendo estas tres últimas convertibles a caracter o factor) y las referentes a coordendas geográficas.
 
```{r transformacion tipos, echo=FALSE}
#Trasformar tipo de CODISTBAR , CODDIS y CODBAR a caracter
fotocasa_compra$CODDISTBAR <- as.character(fotocasa_compra$CODDISTBAR)
fotocasa_compra$CODDIS <- as.character(fotocasa_compra$CODDIS)
fotocasa_compra$CODBAR <- as.character(fotocasa_compra$CODBAR)
```

De las variables restantes sin comentar son de tipo numérico, enfocando que aquellas únicamente numéricas contínuas son las del precio en los años de 2010, 2022 y máximos históricos. No obstante, antes de analizar con las métricas de resumen, hay que realizar un análisis de valores faltantes y duplicados, así como la presencia de valores anómalos que puedan afectar al posterior análisis.

### Duplicados y valores faltantes

```{r filas duplicadas, echo=FALSE}
#Comprobar si hay filas duplicadas
duplicados <- fotocasa_compra[duplicated(fotocasa_compra),]
duplicados
```

No existen filas duplicadas dentro del conjunto de datos. Ahora se procede a comprobar si hay valores nulos en el mismo.

```{r datos faltantes, echo=FALSE}
# Exploración de datos faltantes
colSums(is.na(fotocasa_compra))
```

Hay 18 valores nulos en columnas de máximos históricos y precios de metro cuadrado. Se verifica que barrios son los que tienen valores nulos y a qué distritos pertenecen. Se sabe que los valores faltantes son referentes a los años y precios de metro cuadrado.

```{r exposicion filas nulas, echo=FALSE}
#Exponer filas con valores nulos
fotocasa_compra[!complete.cases(fotocasa_compra),]%>% 
  group_by(DISTRITO) %>% 
  summarise(n = n())
```

Parece que todos son barrios pertenecientes al distrito de poblados del norte, sur y oeste. Cabe responder a la pregunta de si hay distritos completos sin datos o solamente son barrios sueltos dentro de esos distritos.
 
```{r exposicion distritos nulos, echo=FALSE}
#Agrupar por distrito, solo seleccionar distritos POBLATS DE LOEST, POBLATS DEL NORD, POBLATS DEL SUD
fotocasa_compra %>% 
  filter(DISTRITO %in% c("POBLATS DE LOEST", "POBLATS DEL NORD", "POBLATS DEL SUD")) %>% 
  group_by(DISTRITO) %>% 
  summarise(n = n())
```

```{r exposicion distritos nulos especificos, echo=FALSE}
#Exponer distritos POBLATS DE LOEST, POBLATS DEL NORD, POBLATS DEL SUD, con variables de precio
fotocasa_compra %>% 
  filter(DISTRITO %in% c("POBLATS DE LOEST", "POBLATS DEL NORD", "POBLATS DEL SUD")) %>% 
  select(DISTRITO,BARRIO, M2_2022, M2_2010, M2_MAX, AÑO_MAX)
```

Como resultado se observa que de 3 distritos completos no se tienen datos. Esto supone un gran problema, sobreotodo cómo afrontarlo. No se puede eliminar porque suponen una pérdida importante en la representación del conjunto de datos. El mejor caso sería imputar. Si se tiene un dato no nulo pertenenciente a algún barrio dentro de esos distritos se puede imputar ese mismo valor para el resto, pero no es el caso. Se puede aproximar el valor mediante barrios adyacentes, pero tampoco es una representación totalmente fiel.


### Imputación de valores faltantes

Como solución, se procede a imputar los valores faltantes del año 2022 mediante los datos presentados en el portal de búsqueda de inmuebles de Indomio (https://www.indomio.es/mercado-inmobiliario/comunitat-valenciana/valencia-capital/). Se ha tomado como referencia el máximo del año.

Para el caso de 2010, no se ha encontrado información suficiente para realizar una imputación correcta, por lo se decide aproximar por el precio de 2010 de aquellos distritos con un precio por metro cuadrado similar al de los distriros con valores faltantes en 2022:

* POBLATS DEL SUD: 2022 <- 1399 €/m2
* POBLATS DEL NORD: 2022 <- 1352 €/m2
* POBLATS DE LOEST: 2022 <- 1386 €/m2

```{r busqueda media, echo=FALSE}
# Mostrar media de precio por distrito, filtrado entre 1300 y 1450
fotocasa_compra %>% 
  group_by(DISTRITO) %>% 
  summarise(M2_2022 = mean(M2_2022)) %>%  filter(M2_2022 < 1450)
```
```{r media 2010 la olivereta, echo=FALSE}
#Seleccionar media de precios de 2010 del distriro de l'olivereta
fotocasa_compra %>% 
  filter(DISTRITO == "L'OLIVERETA") %>% 
  summarise(M2_2010 = mean(M2_2010))

```

Vemos que el distrito que más se asemeja es el de L'olivereta con 1162 €/m2. Vamos a imputar los valores faltantes de 2022 con este valor.
En resumen, los valores finales son:

* POBLATS DEL SUD: 2022 <- 1399 €/m2, 2010 <- 1162 €/m2
* POBLATS DEL NORD: 2022 <- 1352 €/m2, 2010 <- 1162 €/m2
* POBLATS DE LOEST: 2022 <- 1386 €/m2, 2010 <- 1162 €/m2

```{r}
#Insertar valores faltantes correspondientemente
fotocasa_compra$M2_2022[fotocasa_compra$DISTRITO == "POBLATS DEL SUD"] <- 1399
fotocasa_compra$M2_2022[fotocasa_compra$DISTRITO == "POBLATS DEL NORD"] <- 1352
fotocasa_compra$M2_2022[fotocasa_compra$DISTRITO == "POBLATS DE LOEST"] <- 1386
fotocasa_compra$M2_2010[fotocasa_compra$DISTRITO %in% c("POBLATS DEL SUD", "POBLATS DEL NORD", "POBLATS DE LOEST")] <- 1162
```

```{r}
#Resultado
fotocasa_compra %>% 
  filter(DISTRITO %in% c("POBLATS DE LOEST", "POBLATS DEL NORD", "POBLATS DEL SUD")) %>% 
  select(DISTRITO,BARRIO, M2_2022, M2_2010, M2_MAX, AÑO_MAX)
```

Tras esto, se ratifica si los valores de precio máximo son los correctos. Solo los podemos cotejar con aquellos de los años 2010 y 2022 que son las columnas a las que tenemos acceso, pero aún así, el valor debería ser mínimo que aquellos dos presentados durante esos dos años.

```{r}
# Comprobar que valores máximos son mayores que los de 2010 y 2022
fotocasa_compra %>% 
  filter(M2_MAX < M2_2010 | M2_MAX < M2_2022) %>% 
  select(BARRIO, M2_2022, M2_2010, M2_MAX, AÑO_MAX)
```
 
Se examina 9 casos donde el máximo histórico es menor que el precio de 2010 o 2022. Esto puede deberse a un error humano o de recogida de datos. No puede ser un error de registro, pues todos han sido registrados durante el año 2023 y los registros más recientes son del año 2022. 

Una vez más salta la pregunta de cómo corregir estos errores en la obtención de los datos. No es lo más acertado asignar el valor máximo de la columna de 2010 o de 2022 porque no sabemos a ciencia cierta si son los valores máximos al no tener registros de otros años. Una solución consiste en buscar información cotejada de otras fuentes fiables sobre los valores oportunos o reclamar a la fuente de los datos para que corrijan los errores y presente un conjunto de datos más consistente.

Para este caso, y con el objetivo de corregir lo máximo el conjunto de datos, se cambia el valor máximo por el valor más alto de los dos años, 2010 y 2022. Así además se termina de imputar los datos faltantes de los tres distritos con valores nulos

```{r}
# Seleccionar precio máximo entre las dos variables y escribirlo en M2_MAX y el año en AÑO_MAX
fotocasa_compra$M2_MAX <- pmax(fotocasa_compra$M2_2022, fotocasa_compra$M2_2010)
fotocasa_compra$AÑO_MAX <- ifelse(fotocasa_compra$M2_MAX == fotocasa_compra$M2_2022, "2022", "2010")
```

Con esto finalizamos el análisis de valores nulos e incongruencias en el conjunto de datos. Para el próximo apartado se procede al análisis de los datos (anomalías entre otras ocurrencia) y a la visualización de los mismos para continuar con la línea investigativa del trabajo.


# Análisis preliminar del fichero Salario.

Primeramente, con el propósito de analizar los outliers y las distribuciones de los datos se representó de las tres primeras variables, las categóricas; un histograma con el objetivo de ver si alguna de las categorías tenía una frecuencia de aparición anormalmente pequeña o grande. Cabe destacar que estos no son outliers en sí mismos, dado que este es un concepto referido generalmente a variables numéricas, pero es importante descartar que esto ocurra con las variables categóricas. Asimismo, para las variables numéricas, que son el periodo y el total, se realizó un boxplot para ver si alguna contenia algún valor anómalo.

```{r tabla salario, echo=FALSE}
# Calcular frecuencias por separado y unirlas en una tabla
tabla_combinada <- bind_rows(
  Salario %>%
    group_by(Variable = "Sexo", Valor = Sexo) %>%
    summarise(Frecuencia = n(), .groups = "drop"),
  Salario %>%
    group_by(Variable = "Comunidades_Autonomas", Valor = `Comunidades autónomas`) %>%
    summarise(Frecuencia = n(), .groups = "drop"),
  Salario %>%
    group_by(Variable = "Percentiles_Salario", Valor = `Medidas y percentiles`) %>%
    summarise(Frecuencia = n(), .groups = "drop")
)

# Calcular porcentaje dentro de cada grupo
tabla_combinada <- tabla_combinada %>%
  group_by(Variable) %>%
  mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2))

# Crear la tabla utilizando knitr::kable para PDF
tabla_pdf <- tabla_combinada %>%
  knitr::kable(
    format = "latex",
    booktabs = TRUE,  # Bordes mejorados para PDF
    caption = "Frecuencias y Porcentajes por Variable",
    col.names = c("Variable", "Valor", "Frecuencia", "Porcentaje (%)")
  ) %>%
  kableExtra::kable_styling(
    latex_options = c("hold_position"),  # Ajustar posición y evitar escalas grandes
    position = "center"
  ) %>%
  kableExtra::row_spec(0, bold = TRUE, background = "#FF5733", color = "white") %>%  # Color específico para la fila de encabezados
  kableExtra::column_spec(3, 
    background = ifelse(tabla_combinada$Variable == "Sexo", "#4CAF50", 
                        ifelse(tabla_combinada$Variable == "Comunidades_Autonomas", "#800080", "#0000FF")),
    color = "white") %>%
  kableExtra::column_spec(4, 
    background = ifelse(tabla_combinada$Variable == "Sexo", "#4CAF50", 
                        ifelse(tabla_combinada$Variable == "Comunidades_Autonomas", "#800080", "#0000FF")),
    color = "white") %>%
  kableExtra::row_spec(1:nrow(tabla_combinada), hline_after = FALSE)  # Eliminar espacios en blanco

# Mostrar la tabla
tabla_pdf



```





Como vemos no existe ninguna anomalía en las variables categóricas, dado que todas aparecen con la misma frecuencia 



## Análisis de las variables numéricas

Estudiemos ahora la disposición de las variables numéricas.

```{r boxplot univariante salario, echo=FALSE}
ggplot(Salario, aes(x =`Medidas y percentiles`, y = Total,fill =`Medidas y percentiles`)) +
  geom_boxplot()+theme(axis.text.x = element_text(angle = 45, hjust = 1))+labs(title = 'Boxplot del salario según percentil')
```

Como podemos ver, en casi todos los boxplots aparecen valores atípicos o outliers. Sin embargo, considerando que estamos analizando la evolución de los salarios a lo largo de más de 10 años, estos valores atípicos pueden ser el resultado natural del crecimiento de los salarios durante ese periodo. Además, no observamos valores extremadamente altos o bajos, lo que sugiere que no hay anomalías significativas en los datos, sino simplemente la variabilidad normal de un proceso económico que evoluciona con el tiempo.

```{r distribucion salario, echo=FALSE, message=FALSE, warning=FALSE}
# Crear gráficos de barras con densidad superpuesta
library(patchwork)  # Para combinar múltiples gráficos
percentiles_levels<-levels(Salario$`Medidas y percentiles`)
graficos <- lapply(percentiles_levels, function(level) {
  ggplot(Salario %>% filter(`Medidas y percentiles` == level),
         aes(x = Total, fill = `Medidas y percentiles`)) +
    geom_histogram(aes(y = ..density..), fill = "#FF4500", alpha = 0.6, bins = 30) +  # Cambiar color del histograma para contraste y aumentar transparencia
    geom_density(color = "blue", size = 1, alpha = 0.3) +  # Aumentar transparencia del gráfico de densidad
    labs(title = level, x = "Total (€)", y = "Densidad") +  # Simplificar el título
    theme_minimal() +
    theme(
      legend.position = "none",  # Eliminar la leyenda
      plot.title = element_text(size = 10)  # Reducir el tamaño del título
    )
})

# Combinar los gráficos
grafico_final <- wrap_plots(graficos, ncol = 2)

# Mostrar el conjunto de gráficos
grafico_final
```

Como podemos observar, las distribuciones no parecen ajustarse a una forma gaussiana en ninguno de los casos. Por eso, para definir la distribución, vamos a usar la mediana y el rango intercuartílico, ya que estas métricas no dependen del tipo de distribución que tengan los datos y son más fiables para describir distribuciones asimétricas o con valores atípicos

```{r resumen metricas salario, echo=FALSE}
# Crear tabla con gt para representar cada percentil con la mediana e IQR
metricas_percentiles <- Salario %>%
  group_by(`Medidas y percentiles`) %>%
  # Empleamos los parámetros robustos frente a la distribución de los datos
  summarise(
    Mediana = median(Total, na.rm = TRUE),
    IQR = IQR(Total, na.rm = TRUE)
  )

# Crear la tabla utilizando gt
tabla_metricas <- metricas_percentiles %>%
  gt() %>%
  tab_header(
    title = "Metricas de Salario por Percentil",
    subtitle = "Mediana y Rango Intercuartílico para cada percentil"
  ) %>%
  tab_options(
    table.width = px(700)  # Ajustamos el ancho de la tabla
  ) %>%
  # alineamos el contenido de las columnas
  cols_align(
    align = "center",
    columns = everything()
  )%>%
  fmt_number(
    columns = Mediana,
    suffixing = TRUE,
    pattern = "{x} €"
  )

# Mostrar la tabla
tabla_metricas
```

A partir de la tabla de las métricas de salario por percentil, podemos observar que los valores de la mediana y del rango intercuartílico (IQR) varían de manera significativa entre los diferentes percentiles. La mediana aumenta progresivamente desde 8.720 € en el percentil 10 hasta 39.090 € en el percentil 90. Esto indica un crecimiento notable de los salarios conforme se avanza a percentiles más altos.

El rango intercuartílico (IQR), que nos muestra la variabilidad en los salarios, también crece a medida que se incrementa el percentil. En los percentiles inferiores, como el cuartil inferior y el percentil 10, los valores del IQR se mantienen relativamente bajos, lo cual sugiere una menor dispersión de los salarios. Sin embargo, al avanzar hacia los percentiles superiores, como el cuartil superior y el percentil 90, el IQR incrementa considerablemente, lo cual refleja una mayor variabilidad en los salarios más altos.

Como este análisis se realiza a lo largo de los años, el hecho de que el rango intercuartílico sea más elevado en los percentiles más altos indica que quienes más han aumentado su salario son los del percentil 90. Además, existen diferencias significativas entre lo que cobra la media de la población y el cuartil inferior, lo cual resalta una mayor desigualdad salarial entre la clase media.

# Análisis preliminar del fichero Vivienda.

Los datos numéricos del dataset Vivienda corresponden al IPV. Este es un índice calculado por el INE que busca explicar el precio de la vivienda. Así, dado que este dato ya es en sí profundamente procesado, no creemos que realizar un análisis como el anterior sea ocurrente, pues no encontraríamos outliers o distribuciones interesantes.

# Análisis del archivo Salario

## Evolución del sueldo medio

Primeramente, nos centraremos en ver como ha variado el salario medio de cada comunidad autónoma a lo largo del tiempo. El objetivo de este análisis es ver como ha variado el salario medio en cada comunidad y si existe una tendencia general en las mismas.Por limitaciones de la representación solo se muestran las dos comunidades con mayor salario medio(tomando como referencia 2022) y con menor valor de este. No obstante,en la versión web creada con shiny se puede jugar con todas las comunidades autónomas.

```{r evolucion sueldo medio, echo=FALSE}
primer_analisis<-Salario[Salario$`Medidas y percentiles`=='Media'&Salario$Sexo=='Ambos sexos'& Salario$`Comunidades autónomas`!='Total Nacional',]

# Filtrando las comunidades autónomas con el valor de salario medio de 2022
primer_analisis <- Salario %>%
  filter(`Medidas y percentiles` == 'Media', 
         Sexo == 'Ambos sexos', 
         `Comunidades autónomas` != 'Total Nacional')

# Seleccionando las dos comunidades con mayor y menor salario medio en el 2022 como referencia de la tendencia a lo largo de los años
comunidades_filtradas <- primer_analisis %>%
  filter(Periodo == 2022) %>%
  slice_max(Total, n = 2) %>%
  bind_rows(slice_min(primer_analisis %>% filter(Periodo == 2022), Total, n = 2)) %>%
  select(`Comunidades autónomas`) %>%
  distinct()

# Filtrando los datos para solo incluir las comunidades seleccionadas
primer_analisis_filtrado <- primer_analisis %>%
  filter(`Comunidades autónomas` %in% comunidades_filtradas$`Comunidades autónomas`)

# Crear el gráfico
g1 <- ggplot(primer_analisis_filtrado, aes(x = Periodo, y = Total, color = `Comunidades autónomas`)) +
  geom_line() +
  geom_point() +
  labs(
    title = 'Evolución del Sueldo Medio por CC. AA',
    y = 'Total (€)',
    color = NULL  # Sin título en la leyenda
  ) +
  scale_color_manual(values = coloresCCAA) +  # Colores personalizados
  guides(color = guide_legend(title = NULL))  # Sin título en la leyenda

# Mostrar el gráfico
g1
```

Como se puede observar, las comunidades con mayor salario medio son el País Vasco y Madrid. Por otro lado, las comunidades con peor sueldo medio a lo largo de los años son Extremadura y Canarias. Además se puede ver una clara tendencia al alza en los últimos años, lo que demuestra que el salario medio está subiendo año a año en nuestro país.

### Mapa interactivo

Para terminar este primer análisis, y pese a que no es observable en este pdf, el Rmd incluye un mapa interactivo que muestra la evolución del salario medio en el territorio español.

```{r mapa salario, eval=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
# Descargar el mapa de comunidades autónomas
mapa_espana <- esp_get_ccaa()
# Vemos si existen diferencias entre las etiquetas 
nombres_mapa<-mapa_espana$ine.ccaa.name
nombres_datos <- unique(primer_analisis$`Comunidades autónomas`)
nombres_no_coinciden <- setdiff(nombres_datos, nombres_mapa)
print(nombres_no_coinciden)
# Unir el mapa con tus datos
datos_mapa <- mapa_espana %>%
  left_join(primer_analisis, by = c("ine.ccaa.name" = "Comunidades autónomas"))

# Crear el gráfico animado
mapa_animado <- ggplot(datos_mapa) +
  geom_sf(aes(fill = Total), color = "white") +  # Color de las fronteras de las comunidades
  scale_fill_viridis_c(option = "magma", name = "Salario Medio (€)") +  # Escala de colores
  theme_minimal() +
  labs(
    title = "Evolución del Salario Medio en España ({closest_state})",
    subtitle = "Datos por Comunidad Autónoma",
    caption = "Fuente: INE",
    fill = "Salario (€)"
  ) +
  transition_states(Periodo, state_length = 1, wrap = FALSE) +  # Animación por año
  ease_aes("linear")  # Suaviza las transiciones

# Renderizar el mapa animado
animate(
  mapa_animado,
  nframes = 150,  # Más cuadros
  fps = 10,        # Menor cantidad de cuadros por segundo
  width = 800,
  height = 600
)
```

## Discrepancias de género a lo largo de los años

Aprovechando la variable `sexo` presente en el dataset, pasamos a estudiar las discrepancias de salario respecto al género a lo largo de los años.

```{r evolucion genero salario, echo=FALSE}
# Filtrando los datos con dplyr
segundo_análisis_A <- Salario %>%
  filter(`Comunidades autónomas` == 'Total Nacional',
         `Medidas y percentiles` == 'Media',
         Sexo != 'Ambos sexos')

# Creando la gráfica con ggplot2
g2 <- ggplot(segundo_análisis_A, aes(x = Periodo, y = Total, fill = Sexo)) +
  geom_bar(stat = "identity", position = 'dodge') +
  scale_fill_manual(values = coloresHM) +
  geom_line(aes(group = Sexo, color = Sexo)) +
  geom_point(aes(color = Sexo)) +
  labs(
    title = 'Discrepancias de Género en el Salario Medio a Nivel Nacional',
    y = 'Total (€)',
    x = 'Periodo'
  ) +
  theme_minimal()

# Mostrando la gráfica
g2
```

Como se puede observar, desde el 2008 hasta el 2022 tanto el salario medio de las mujeres como el de los hombres ha experimentado un aumento sustancial. Pasando, aporximadamente de los 24000€ a los 29000€ en el caso de los hombres y de los  18000€ a los 24000€ en las mujeres. Sin embargo, y pese a que la diferencia ha diminuído con respecto a los hombres, las mujeres cobran de media aproximadamente lo mismo en el 2022 que los hombres en el 2008, dato que llama la atención y cuyas causas deberían ser estudiadas más en profundidad.

### Discrepancias de género por comunidad

A continuación, calculamos la brecha salarial media en cada comunidad autónoma y observamos su evolución en unas pocas.

```{r brecha salarial por ccaa, echo=FALSE}
# Filtramos las comunidades autónomas excluyendo "Total Nacional" y seleccionamos solo la media y el sexo que no sea "Ambos sexos"
df_filtered <- Salario %>%
  filter(`Comunidades autónomas` != 'Total Nacional', 
         `Medidas y percentiles` == 'Media', 
         Sexo != 'Ambos sexos') %>%
  select(-`Medidas y percentiles`)

# Transformamos los datos para obtener la diferencia entre Hombres y Mujeres
df_filtered <- df_filtered %>%
  pivot_wider(names_from = Sexo, values_from = Total) %>%
  mutate(diferencia = Hombres - Mujeres)

# Filtramos las comunidades con las dos mayores y las dos menores diferencias en el año 2022
df_filtered_2022 <- df_filtered %>%
  filter(Periodo == 2022) %>%
  slice_max(order_by = diferencia, n = 2) %>%
  bind_rows(slice_min(df_filtered %>% filter(Periodo == 2022), order_by = diferencia, n = 2))

# Filtramos el dataset original para obtener las comunidades seleccionadas
comunidades_seleccionadas <- df_filtered_2022$`Comunidades autónomas`

df_filtered_final <- df_filtered %>%
  filter(`Comunidades autónomas` %in% comunidades_seleccionadas)

# Graficamos las diferencias a lo largo de los años
g4 <- ggplot(df_filtered_final, aes(x = Periodo, y = diferencia, color = `Comunidades autónomas`)) +
  geom_line() +
  geom_point() +
  scale_color_manual(values = coloresCCAA) +  # Colores personalizados
  guides(color = guide_legend(title = NULL)) +
  labs(title = 'Análisis de discrepancias de género por años y comunidades',
       y = 'Diferencia (€)')

print(g4)
```

Como vemos, las comunidades con la menor diferencia de salario medio entre hombres y mujeres son las Islas Canarias, las Islas Baleares y Extremadura. Este dato es sorprendente, porque justamente las Islas Canarias y Extremadura son las dos comunidades autónomas con menor salario medio.

## App interactiva con Shiny del dataset Salario

Finalmente, y pese a que no se muestree por las limitaciones del formato PDF, se incluye una página web creada con Shiny para poder observar el análisis de manera interactiva.

```{r app salario, eval=FALSE, include=FALSE}
# Crear la interfaz de usuario
ui <- fluidPage(
  titlePanel("Evolución del Sueldo Medio por CC. AA"),
  sidebarLayout(
    sidebarPanel(
      sliderInput("año", "Selecciona los años a mostrar:",
                  min = min(primer_analisis$Periodo),
                  max = max(primer_analisis$Periodo),
                  value = range(primer_analisis$Periodo),
                  step = 1,
                  sep = ""),
      checkboxGroupInput("comunidades", "Selecciona las Comunidades Autónomas:",
                         choices = unique(primer_analisis$`Comunidades autónomas`),
                         selected = unique(primer_analisis$`Comunidades autónomas`))
    ),
    mainPanel(
      tabsetPanel(
        tabPanel("Evolución del Sueldo Medio", plotOutput("salarioPlot")),
        tabPanel("Análisis de Discrepancias de Género", plotOutput("discrepanciasGeneroPlot"))
      )
    )
  )
)

# Definir la lógica del servidor
server <- function(input, output) {
  # Pestaña 1: Evolución del Sueldo Medio
  output$salarioPlot <- renderPlot({
    # Filtrar los datos según los años y comunidades seleccionadas
    datos_filtrados <- primer_analisis %>%
      filter(Periodo >= input$año[1],
             Periodo <= input$año[2],
             `Comunidades autónomas` %in% input$comunidades)
    
    # Crear el gráfico con los datos filtrados
    ggplot(datos_filtrados, aes(x = Periodo, y = Total, color = `Comunidades autónomas`)) +
      geom_line() +
      geom_point() +
      labs(
        title = 'Evolución del Sueldo Medio por CC. AA',
        y = 'Total (€)',
        color = NULL  # Sin título en la leyenda
      ) +
      scale_color_manual(values = coloresCCAA) +  # Colores personalizados
      guides(color = guide_legend(title = NULL))  # Sin título en la leyenda
  })
  
  # Pestaña 2: Análisis de Discrepancias de Género
  output$discrepanciasGeneroPlot <- renderPlot({
    # Filtrar los datos para el análisis de discrepancias de género
    df_filtered <- Salario[Salario$`Comunidades autónomas` != 'Total Nacional' &
                             Salario$`Medidas y percentiles` == 'Media' &
                             Salario$Sexo != 'Ambos sexos', ]
    df_filtered <- df_filtered[, !names(df_filtered) %in% 'Medidas y percentiles']
    # Emplear pivot_wider para transformar los datos
    df_filtered <- pivot_wider(df_filtered, names_from = Sexo, values_from = Total)
    df_filtered$diferencia <- df_filtered$Hombres - df_filtered$Mujeres
    
    # Crear el gráfico de discrepancias de género
    ggplot(df_filtered, aes(x = Periodo, y = diferencia, color = `Comunidades autónomas`)) +
      geom_line() +
      geom_point() +
      scale_color_manual(values = coloresCCAA) +  # Colores personalizados
      guides(color = guide_legend(title = NULL)) +
      labs(title = 'Análisis de discrepancias de género por años y comunidades', y = 'Diferencia (€)')
  })
}

# Ejecutar la aplicación Shiny
shinyApp(ui = ui, server = server)
```

# Análisis del dataset Vivienda.

En este dataset se analiza el IPV (Índice de Precios de Vivienda) dependiendo del año, región o tipo de vivienda. Para poder entender correctamente el siguiente análisis, tenemos que explicar brevemente en que consiste el IPV.

El IPV tiene como principal objetivo medir la evolución del nivel de los precios de compraventa de las viviendas de precio libre, nuevas y de segunda mano, a lo largo del tiempo. Se trata, por tanto, de un indicador concebido únicamente para establecer comparaciones en el tiempo.

Una vez aclarado el concepto del IPV, pasamos al análisis de nuestro datatset.

## Evolución del IPV a lo largo de los años por región.

La principal información que recoge este dataset es el del valor del IPV a lo largo de los años. Así, empezaremos estudiando la evolución del IPV del $2007$ al $2022$. Además, aprovecharemos el hecho de que los datos están seccionados por autonomías, para comparar dicha evolución.

```{r vivienda comunidades, echo=FALSE}
#Escogemos los datos necesarios
Vivienda1 <- Vivienda %>%
  filter(`Comunidades y Ciudades Autónomas` %in% particionCCAA,
         `General, vivienda nueva y de segunda mano`=='General', 
         `Índices y tasas`=='Media anual')

#Creamos el gráfico
ggplot(Vivienda1, aes(x = Periodo, y = Total, color = `Comunidades y Ciudades Autónomas`)) +
  geom_line() +
  geom_point() +
  scale_color_manual(values = coloresparticiónCCAA) +
  labs(
    title = 'Evolución del IPV por Comunidades Autónomas',
    y = 'IPV',
    x = 'Año',
    color = NULL  # Sin título en la leyenda
  ) +
  guides(color = guide_legend(title = NULL))  # Sin título en la leyenda
```

Como podemos ver, el IPV sufrió una gran caída a partir del año $2008$, posiblemente por el estallido de la burbuja inmobiliaria. Dicha caída continua hasta frenarse en el año $2015$, donde sigue una subida constante hasta la actualidad.

Respecto a la comparativa por autonomías, vemos como Madrid, Cataluña y Canarias  obtienen los mayores valores del IPV actual, por encima del valor nacional. Por otro lado, Extremadura, Navarra y las castillas tienen el IPV más bajo de todas las comunidades autónomas.

Esta diferencia de valores puede ser motivo de las preferencias del sector turístico, pues Madrid, Cataluña y Canarias son comunidades altamente turísticas, en contraste a las otras comunidades.

### Mapa interactivo

Si bien ya podíamos visualizar tendencias y sacar conclusiones en el anterior gráfico, el siguiente mapa (no disponible en pdf) ayudará a afinar dichas conclusiones.

```{r mapa vivienda, echo=FALSE, eval=FALSE}
#Eliminamos el total nacional
ViviendaMapa <- Vivienda %>%
  filter(`General, vivienda nueva y de segunda mano`=='General', 
         `Índices y tasas`=='Media anual', 
         `Comunidades y Ciudades Autónomas` != 'Total Nacional')

# Unir el mapa con tus datos
datos_mapa_vivienda <- mapa_espana %>%
  left_join(ViviendaMapa, by = c("ine.ccaa.name" = "Comunidades y Ciudades Autónomas"))

# Crear el gráfico animado
mapa_animado_vivienda <- ggplot(datos_mapa_vivienda) +
  geom_sf(aes(fill = Total), color = "white") +  # Color de las fronteras de las comunidades
  scale_fill_viridis_c(option = "magma", name = "IPV") +  # Escala de colores
  theme_minimal() +
  labs(
    title = "Evolución del IPV en España ({closest_state})",
    subtitle = "Datos por Comunidad Autónoma",
    caption = "Fuente: INE",
    fill = "IPV"
  ) +
  transition_states(Periodo, state_length = 1, wrap = FALSE) +  # Animación por año
  ease_aes("linear")  # Suaviza las transiciones

# Renderizar el mapa animado
animate(
  mapa_animado,
  nframes = 150,  # Más cuadros
  fps = 10,        # Menor cantidad de cuadros por segundo
  width = 800,
  height = 600
)
```

## Viviendas nueva y de segunda mano

El dataset también nos ofrece información sobre la diferencia entre el IPV de viviendas nuevas y de segunda mano. Veamos la distinta evolución a nivel nacional.

```{r tipos de vivienda, echo=FALSE}
#Escogemos los datos necesarios
Vivienda2 <- Vivienda %>%
  filter(`Comunidades y Ciudades Autónomas` == 'Total Nacional',
         `Índices y tasas`=='Media anual',
         `General, vivienda nueva y de segunda mano`!='General')

#Crear el gráfico
  ggplot(Vivienda2,aes(x = Periodo, y = Total, fill = `General, vivienda nueva y de segunda mano`)) +
    geom_bar(stat = "identity",position = 'dodge') +
    scale_fill_manual(values = coloresNS) +
    geom_line() +
    geom_point() +
    labs(
    title = 'Evolución del IPV nacional por tipo de vivienda',
    y = 'IPV',
    x = 'Año',
    fill = "Tipo de vivienda"
    )
```

Como podemos observar, $2015$ vuelve a ser un punto de inflexión, pues en este caso pasamos de ver un IPV mayor en las viviendas de segunda mano, a un mayor IPV en las nuevas viviendas.

### IPV de vivienda nueva y de segunda mano por comunidades autónomas

Para terminar con este análisis, representaremos la diferencia entre el IPV de nuevas viviendas y viejas viviendas en toda España, contrastando nuestra conclusión previa.

```{r diferencia SN, echo=FALSE}
# Filtrar los datos para el análisis de vivienda nueva y de segunda manp
Vivienda3 <- Vivienda %>%
  filter(`Comunidades y Ciudades Autónomas` %in% particionCCAA,
         `Índices y tasas`=='Media anual',
         `General, vivienda nueva y de segunda mano`!='General')

# Emplear pivot_wider para transformar los datos
Vivienda3 <- pivot_wider(Vivienda3, names_from = `General, vivienda nueva y de segunda mano`, values_from = Total)
Vivienda3$Diferencia <- Vivienda3$`Vivienda nueva` - Vivienda3$`Vivienda segunda mano`

# Graficamos las diferencias a lo largo de los años
  ggplot(Vivienda3,aes(x = Periodo, y = Diferencia, color = `Comunidades y Ciudades Autónomas`)) +
    geom_line() +
    geom_point() +
    scale_color_manual(values = coloresparticiónCCAA) +  # Colores personalizados
    guides(color = guide_legend(title = NULL)) +
    labs(title = 'Análisis de diferencia de IPV entre viviendas nuevas y de segunda mano',
         y = 'Diferencia IPV'
    )
```

## App interactiva con Shiny del dataset Vivienda

Para finalizar nuestro análisis de los datos del IPV en España, creamos la siguiente aplicación que permite observar con mayor claridad, y de manera personalizada, los gráficos presentados. (No disponible en pdf)

```{r app vivienda, eval=FALSE, include=FALSE}
# Crear la interfaz de usuario
ui_vivienda <- fluidPage(
  titlePanel("Evolución del IPV por CCAA"),
  sidebarLayout(
    sidebarPanel(
      sliderInput("Año", "Selecciona los años a mostrar:",
                  min = min(Vivienda1$Periodo),
                  max = max(Vivienda1$Periodo),
                  value = range(Vivienda1$Periodo),
                  step = 1,
                  sep = ""),
      checkboxGroupInput("Comunidades y ciudades", "Selecciona las CCAA:",
                         choices = unique(Vivienda1$`Comunidades y Ciudades Autónomas`),
                         selected = unique(Vivienda1$`Comunidades y Ciudades Autónomas`))
    ),
    mainPanel(
      tabsetPanel(
        tabPanel("Evolución del IPV", plotOutput("IPVPlot")),
        tabPanel("Análisis de las viviendas nuevas y de segunda mano", plotOutput("NSViviendaPlot"))
      )
    )
  )
)

# Definir la lógica del servidor
server_vivienda <- function(input, output) {
  # Pestaña 1: Evolución del Sueldo Medio
  output$IPVPlot <- renderPlot({
    # Filtrar los datos según los años y comunidades seleccionadas
    datos_filtrados_vivienda_IPV <- Vivienda1 %>%
      filter(Periodo >= input$Año[1],
             Periodo <= input$Año[2],
             `Comunidades y Ciudades Autónomas` %in% input$`Comunidades y ciudades`)
    
    # Crear el gráfico con los datos filtrados
    ggplot(datos_filtrados_vivienda_IPV, aes(x = Periodo, y = Total, color = `Comunidades y Ciudades Autónomas`)) +
      geom_line() +
      geom_point() +
      labs(
        title = 'Evolución del IPV por CCAA',
        y = 'IPV',
        color = NULL  # Sin título en la leyenda
      ) +
      scale_color_manual(values = coloresCCAA) +  # Colores personalizados
      guides(color = guide_legend(title = NULL))  # Sin título en la leyenda
  })
  
  # Pestaña 2: Análisis de Discrepancias de Género
  output$NSViviendaPlot <- renderPlot({
    # Filtrar los datos para el análisis de discrepancias de género
    ViviendaDiff <- Vivienda[Vivienda$`Comunidades y Ciudades Autónomas` != 'Total Nacional' &
                             Vivienda$`Índices y tasas` == 'Media anual' &
                             Vivienda$`General, vivienda nueva y de segunda mano` != 'General', ]
    # Emplear pivot_wider para transformar los datos
    ViviendaDiff <- pivot_wider(ViviendaDiff, names_from = `General, vivienda nueva y de segunda mano`, values_from = Total)
    ViviendaDiff$Diferencia <- ViviendaDiff$`Vivienda nueva` - ViviendaDiff$`Vivienda segunda mano`
    
    # Crear el gráfico de discrepancias de género
    ggplot(ViviendaDiff, aes(x = Periodo, y = Diferencia, color = `Comunidades y Ciudades Autónomas`)) +
      geom_line() +
      geom_point() +
      scale_color_manual(values = coloresCCAA) +  # Colores personalizados
      guides(color = guide_legend(title = NULL)) +
      labs(title = 'Análisis de diferencia en IPV entre vivienda nueva y de segunda mano', y = 'Diferencia de IPV')
  })
}

# Ejecutar la aplicación Shiny
shinyApp(ui = ui_vivienda, server = server_vivienda)
```
#Análisis preliminar del fichero Precio M2 Valencia

## Análisis de valores

```{r boxplot precio m2, echo=FALSE}
# Boxplot para detectar outliers en cada variable numérica
fotocasa_compra %>% 
  select(where(is.numeric)) %>%
  gather(key = "Precio_m2", value = "Euros") %>%
  ggplot(aes(x = Precio_m2, y = Euros, fill = Precio_m2))  +
  geom_boxplot(alpha = 0.7) + 
  labs(title = "Boxplot de precios por metro cuadrado") + 
  theme_minimal()
```

Del resultado de la gráfica de caja  podemos observar que la tendencia evolutiva de los precios a sido a la alza. La media para el año de 2010 fue de 1677,193€/m2, mientras que para el año 2022 fue de 1959,330€/m2. El precio máximo histórico fue de 2022.193€/m2 en el año 2022, mientras que el precio mínimo fue de 1677.193€/m2 en el año 2010. Esto supone un incremento de 282.137€/m2 en 12 años. El diagrama también muestra que el primer cuartil es similar en ambos años, mientras que el tercer cuartil es mayor en el año 2022. Esto indica que la distribución de los precios de 2022 es más dispersa que la de 2010. Esto se nota aún más en los máximos y mínimos. Los valores de 2010 se centraban en el rango de los 1162€/m2 a los 2455€/m2, mientras que en 2022 se centran en el rango de los 1103€/m2 a los 4029€/m2. Sorprende la presencia de valores tan altos en 2022, duplicando el precio máximo de 2010 en casi un 60%. Por otro lado, los mínimos de ambos años son muy similares, lo que indica que los precios mínimos no han variado mucho en estos 12 años.   

Como observación, en el año 2022 existe un dato anómalo que se aleja mucho del resto de los datos. Este valor anómalo es el precio de 4029€/m2. Este valor es un 60% mayor que el precio máximo de 2010. Se comprueba qué barrio es y a que distrito pertenece.

```{r barrio anómalo, echo=FALSE}
#Seleccionar fila con valor máximo del 2022
fotocasa_compra %>% 
  filter(M2_2022 == 4029) %>%
  select(DISTRITO, BARRIO, M2_2010, M2_2022, M2_MAX, AÑO_MAX)
```
El barrio resultantes es El pla del, del distrito de L'Eixample. En su comparación con el precio en 2022, se comprueba que ha duplicado prácticamente el precio máximo de 2010. Al hecho de que se trata de un distrito céntrico y turístico, en pleno casco histórico de la ciudad de Valencia, el valor sigue siendo extraño. Si se compara con otros barrios del distrito donde la evolución ha sido más estable (por ejemplo Russafa de 2106€/m2 a 2738€/m2 o La Gran Via de 2106€/m2 a 3237€/m2). Se puede argumentar al aumento con los años del turismo y el auge de las casas de alquiler vacacional, la gentrificación o el aumento de los nómadas digitales. 

```{r histograma m2, echo=FALSE}
# Histograma de todas las variables numéricas 
fotocasa_compra %>% 
  select(where(is.numeric)) %>%
  gather(key = "Variable", value = "Valor") %>%
  ggplot(aes(x = Valor, fill = Variable)) +
  geom_histogram(bins = 30, alpha = 0.7) +
  facet_wrap(~ Variable, scales = "free") +
  labs(title = "Distribución de Variables Numéricas") +
  theme_minimal()
```

Viendo estos resultados, se presencia las mismas observaciones que nos deja el análisis del diagrama de caja. Los precios de 2010 siguen una distribución más uniforme en un rango más cerrado entre los 1162€/m2 y los 2455€/m2. Por otro lado, los precios de 2022 se dispersan más, con un rango de 1103€/m2 a 4029€/m2, reafirmando una vez más la evolución a la alza de los precios. No obstante, cabe mencionar la similitud entre los histogramas de máximos históricos y precios de 2022. Esto indica que los precios máximos de 2022 se han disparado y apuntalando a ser los máximos históricos alcanzados a la misma vez.



## Análisis por distritos 

Uno de los aspectos más relevantes comparativamente es agrupar los precios por distrito y ver cómo ha evolucionado el precio por metro cuadrado en cada uno de ellos. Se realiza gráfico de barras para ver la evolución de los precios en los años 2010 y 2022.

```{r}
# Gráfico de barras de la media de precios por metro cuadrado en los años 2010 y 2022 por distrito
fotocasa_compra %>% 
  group_by(DISTRITO) %>% 
  summarise(M2_2010 = mean(M2_2010), M2_2022 = mean(M2_2022)) %>% 
  gather(key = "Año", value = "Precio_m2", M2_2010, M2_2022) %>% 
  ggplot(aes(x = reorder(DISTRITO, Precio_m2), y = Precio_m2, fill = Año)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Precio medio por metro cuadrado en 2010 y 2022 por distrito", x = "Distrito", y = "Precio por metro cuadrado") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
#Contar número de medias que han sido superadas en 2022
fotocasa_compra %>% 
  group_by(DISTRITO) %>% 
  summarise(M2_2010 = mean(M2_2010), M2_2022 = mean(M2_2022)) %>% 
  filter(M2_2022 > M2_2010) %>% 
  nrow()
```
Aunque la tendencia del precio ha sido de aumentar, al cotejar los distintos distritos observamos que en la mayoría de los casos no han sido así. En un total de 15 distritos de los 19, el precio medio por metro cuadrado en 2022 ha superado al de 2010. 

```{r}
#Gráfica de barras del porcentaje de aumento o disminución de la media de precio por metro cuadrado entre 2010 y 2022 para cada distrito, con el valor en cada barra y colores rojo para aumento y verde para disminucion
fotocasa_compra %>% 
  group_by(DISTRITO) %>% 
  summarise(M2_2010 = mean(M2_2010, na.rm = TRUE), M2_2022 = mean(M2_2022, na.rm = TRUE)) %>% 
  mutate(Porcentaje = ((M2_2022 - M2_2010) / M2_2010) * 100) %>% 
  ggplot(aes(x = reorder(DISTRITO, Porcentaje), y = Porcentaje, fill = Porcentaje > 0)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = sprintf("%.1f%%", Porcentaje)), 
            position = position_stack(vjust = 0.5), 
            size = 2.5, 
            color = "black") +
  labs(title = "Porcentaje de aumento o disminución de la media de precio por metro cuadrado entre 2010 y 2022 por distrito", 
       x = "Distrito", 
       y = "Porcentaje") +
  scale_fill_manual(values = c("green", "red"), labels = c("Disminución", "Aumento")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Los distritos que han experimentado un mayor aumento de precio son los distritos de Quatre Carreres (63,1%), L'Eixample (58,3%) y Poblats Marítims (39,1%). Por otro lado, los distritos de Benimaclet (3,2%), Campanar (10,7%) y Benicalap (20,5%) han experimentado un descenso en el precio medio por metro cuadrado en 2022 respecto a 2010. Esto indica una vez más que la evolución de los precios no ha sido uniforme en la ciudad de Valencia. Se puede justificar estas diferencias a la localización de los distritos, la presencia de servicios, la calidad de vida, la gentrificación o la presencia de turismo. Por ejemplo, los tres primeros distritos pertenecen a la zona centro de la ciudad (L'Eixample), tienen barrios cercanos al centro (Quatre Carrerer) o están cerca del paseo marítimo (Poblats Marítims). Por otro lado, los tres últimos distritos pertenecen a la periferia de la ciudad y son distritos más residenciales, más lejos de los servicios y de la zona turística; como es el caso de Benicalap o Benimaclet. Aun así resalta el descenso de precios en Campanar, una zona bien comunicada y con buenos servicios, en los que destacar los barrios de Campanar propiamente o El Calvari. 

## Análisis por barrios 

Como hincapié a este análisis, se hace un enfoque en el cambio de precios para cada barrio y comprobar si la tendencia es la misma que en los distritos a los que pertenece. Para ello vamos a observar los casos de los 10 primeros barrios con mayor aumento y los 10 primeros con mayor descenso de precio por metro cuadrado.

```{r}
fotocasa_compra_high <- fotocasa_compra %>%
  mutate(DIF_BARRIO = ((M2_2022 - M2_2010) / M2_2010) * 100) %>%
  arrange(desc(DIF_BARRIO)) %>%  # Ordenar de mayor a menor porcentaje
  slice_head(n = 10)  # Seleccionar los 10 primeros barrios

fotocasa_compra_low <- fotocasa_compra %>%
  mutate(DIF_BARRIO = ((M2_2022 - M2_2010) / M2_2010) * 100) %>%
  arrange(desc(DIF_BARRIO)) %>%  # Ordenar de mayor a menor porcentaje
  slice_tail(n = 10) 

#Juntar ambos datasets
fotocasa_compra_high <- rbind(fotocasa_compra_high, fotocasa_compra_low)

#Gráfico de barras
ggplot(fotocasa_compra_high, aes(x = reorder(BARRIO, DIF_BARRIO), y = DIF_BARRIO, fill = DIF_BARRIO < 0)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = sprintf("%.1f%%", DIF_BARRIO)), 
            vjust = -0.5, size = 2) +
  labs(
    title = "Porcentaje de aumento por metro cuadrado",
    x = "Barrio",
    y = "Porcentaje"
  ) +
  scale_fill_manual(values = c("red", "green"), labels = c("Aumento", "Disminución")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


Vemos que para los 10 barrios con mayor aumento todos pertenecen a distritos cuya diferencia de precios fue de un aumento, como es el caso de Quatre Carreres, L'Eixample o Extramurs. Se destaca el barrio de Ciutat de les Arts i les Ciències con un aumento de del 126,24%, muy por encima incluso del segundo barrio (El Pla del Real) con un aumento del 91,31%, casi una diferencia de 35 puntos porcentuales. 

En el caso de los 10 barrios con mayor descenso de precio, se observa como diferencia barrios pertenecientes a distritos con aumento de precio. Este es el caso del barrio de Natzaret en el distrito de Poblats Marítims, Cami Real en el distrito de Jesus. Esto da a entender que aunque haya distritos con aumento de precio, no quiere indicar que la tendencia de sus barrios haya sido de la misma manera.

Con esto se da por finalizado este apartado del análisis de la tendencia del precio por metro cuadrado para los distintos barrios de la ciudad de Valencia.


# Conclusion

El análisis realizado nos permite comprender mejor las dinámicas entre el precio de la vivienda y los salarios en España. Se observaron patrones relevantes que reflejan desafíos en términos de accesibilidad y sostenibilidad económica para la población. Este estudio resalta la importancia de contar con políticas efectivas que aborden estas disparidades y fomenta la reflexión sobre cómo las tendencias actuales pueden afectar el bienestar socioeconómico en el futuro.
